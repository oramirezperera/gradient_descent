# gradient_descent
creating a gradient descent for a  elliptic paraboloid in Google Colab

## Elliptic paraboloid
z = x^2 + y^2

## Gradient descent
[Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.

Is important to remember that the gradient descent only works for local minimum if you have a non-convex optimization problem, you will need a different optimization algorithm.
